{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amazon Reviews Dataset\n",
    "\n",
    "This is a dataset of Amazon Reviews and one column has the actual text we want to examine. Follow the tasks below to do so and perform sentiment analysis on the text, creating a new column that displays either positive, negative, or neutral.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Read in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id       asins   brand                  categories  \\\n",
      "0  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
      "1  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
      "2  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
      "3  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
      "4  AVpe7AsMilAPnD_xQ78G  B00QJDU3KY  Amazon  Amazon Devices,mazon.co.uk   \n",
      "\n",
      "  colors             dateAdded           dateUpdated  \\\n",
      "0    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
      "1    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
      "2    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
      "3    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
      "4    NaN  2016-03-08T20:21:53Z  2017-07-18T23:52:58Z   \n",
      "\n",
      "                  dimension  ean                         keys  ...  \\\n",
      "0  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
      "1  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
      "2  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
      "3  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
      "4  169 mm x 117 mm x 9.1 mm  NaN  kindlepaperwhite/b00qjdu3ky  ...   \n",
      "\n",
      "  reviews.rating                                 reviews.sourceURLs  \\\n",
      "0            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
      "1            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
      "2            4.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
      "3            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
      "4            5.0  https://www.amazon.com/Kindle-Paperwhite-High-...   \n",
      "\n",
      "                                        reviews.text  \\\n",
      "0  I initially had trouble deciding between the p...   \n",
      "1  Allow me to preface this with a little history...   \n",
      "2  I am enjoying it so far. Great for reading. Ha...   \n",
      "3  I bought one of the first Paperwhites and have...   \n",
      "4  I have to say upfront - I don't like coroporat...   \n",
      "\n",
      "                                reviews.title reviews.userCity  \\\n",
      "0              Paperwhite voyage, no regrets!              NaN   \n",
      "1           One Simply Could Not Ask For More              NaN   \n",
      "2  Great for those that just want an e-reader              NaN   \n",
      "3                    Love / Hate relationship              NaN   \n",
      "4                                   I LOVE IT              NaN   \n",
      "\n",
      "   reviews.userProvince    reviews.username  sizes upc     weight  \n",
      "0                   NaN          Cristina M    NaN NaN  205 grams  \n",
      "1                   NaN               Ricky    NaN NaN  205 grams  \n",
      "2                   NaN       Tedd Gardiner    NaN NaN  205 grams  \n",
      "3                   NaN              Dougal    NaN NaN  205 grams  \n",
      "4                   NaN  Miljan David Tanic    NaN NaN  205 grams  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# TODO: Load the dataset (replace 'your_dataset.csv' with the actual file name)\n",
    "df = pd.read_csv('data/amazonReviews.csv')\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Clean the Text Data\n",
    "\n",
    "Remove unwanted characters, convert text to lowercase, and strip extra spaces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # TODO: Convert text to lowercase \n",
    "    text = text.lower()\n",
    "    \n",
    "    # TODO: Remove special characters and digits\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    \n",
    "    # TODO: Strip extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Apply cleaning function\n",
    "df['clean_text'] = df['reviews.text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Tokenize the Text\n",
    "\n",
    "Split text into individual words (tokens).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  \\\n",
      "0  i initially had trouble deciding between the p...   \n",
      "1  allow me to preface this with a little history...   \n",
      "2  i am enjoying it so far great for reading had ...   \n",
      "3  i bought one of the first paperwhites and have...   \n",
      "4  i have to say upfront i dont like coroporate h...   \n",
      "\n",
      "                                              tokens  \n",
      "0  [i, initially, had, trouble, deciding, between...  \n",
      "1  [allow, me, to, preface, this, with, a, little...  \n",
      "2  [i, am, enjoying, it, so, far, great, for, rea...  \n",
      "3  [i, bought, one, of, the, first, paperwhites, ...  \n",
      "4  [i, have, to, say, upfront, i, dont, like, cor...  \n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "# TODO: Apply word tokenization\n",
    "df['tokens'] = df['clean_text'].apply(word_tokenize)\n",
    "print(df[['clean_text', 'tokens']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Remove Stopwords\n",
    "\n",
    "Eliminate common stopwords that do not contribute much meaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              tokens  \\\n",
      "0  [i, initially, had, trouble, deciding, between...   \n",
      "1  [allow, me, to, preface, this, with, a, little...   \n",
      "2  [i, am, enjoying, it, so, far, great, for, rea...   \n",
      "3  [i, bought, one, of, the, first, paperwhites, ...   \n",
      "4  [i, have, to, say, upfront, i, dont, like, cor...   \n",
      "\n",
      "                                     filtered_tokens  \n",
      "0  [initially, trouble, deciding, paperwhite, voy...  \n",
      "1  [allow, preface, little, history, casual, read...  \n",
      "2  [enjoying, far, great, reading, original, fire...  \n",
      "3  [bought, one, first, paperwhites, pleased, con...  \n",
      "4  [say, upfront, dont, like, coroporate, hermeti...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/jff/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    # TODO: Filter out stopwords\n",
    "    return [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Apply stopword removal\n",
    "df['filtered_tokens'] = df['tokens'].apply(remove_stopwords)\n",
    "print(df[['tokens', 'filtered_tokens']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Convert Text into Numerical Representation\n",
    "\n",
    "Use TF-IDF (Term Frequency-Inverse Document Frequency) to convert text into a numerical format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(775, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TODO: Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "\n",
    "# TODO: Fit and transform the text data\n",
    "X = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "print(X.shape)  # Display shape of transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6: Perform Basic Sentiment Analysis\n",
    "\n",
    "Classify text as positive or negative using a simple rule-based approach.\n",
    "For textblob, a polarity > 1 = Positive, polarity < 1 = negative and a polarity of 0 = neutral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          clean_text  sentiment\n",
      "0  i initially had trouble deciding between the p...   0.199715\n",
      "1  allow me to preface this with a little history...   0.155127\n",
      "2  i am enjoying it so far great for reading had ...   0.420833\n",
      "3  i bought one of the first paperwhites and have...   0.143352\n",
      "4  i have to say upfront i dont like coroporate h...   0.267086\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def get_sentiment(text):\n",
    "    # TODO: Compute polarity score\n",
    "    blob = TextBlob(text)\n",
    "    return blob.sentiment.polarity\n",
    "    \n",
    "\n",
    "# Apply sentiment analysis\n",
    "df['sentiment'] = df['clean_text'].apply(get_sentiment)\n",
    "print(df[['clean_text', 'sentiment']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSB320",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
